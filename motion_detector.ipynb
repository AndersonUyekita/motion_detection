{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b482dab4-8348-4166-9be1-407a7706ab8a",
   "metadata": {},
   "source": [
    "# Motion Detector\n",
    "\n",
    "Esse script visa obter os frames que possuam alguma movimentação que seja de animais silvestres.\n",
    "\n",
    "O funcionamento base será a partir do uso do OpenCV (`cv2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f5ff14-16b7-41d8-8e18-dbc51a393fd5",
   "metadata": {},
   "source": [
    "## 1. _Packages_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0122e5c6-3401-4d63-b731-6de5efc77cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd800d6-6043-47da-9b30-6a246e9bf01e",
   "metadata": {},
   "source": [
    "## 2. Funções\n",
    "\n",
    "### 2.1. `get_motion_mask`\n",
    "\n",
    "* **Objetivo:** A função `get_motion_mask` processa uma máscara de primeiro plano (foreground mask, fg_mask) para destacar regiões onde há movimento detectado, reduzindo ruídos e melhorando a clareza da detecção.\n",
    "\n",
    "A função `get_motion_mask` é responsável por processar a máscara de movimento bruta (fg_mask), aplicando operações de limiarização, suavização e morfologia para destacar áreas de movimento relevantes e minimizar falsos positivos devido a ruídos. O resultado é uma máscara binária mais precisa que pode ser usada para detecção e rastreamento de objetos em movimento em vídeos.\n",
    "\n",
    "```py\n",
    "# Valor inicial\n",
    "kernel_size = 9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443cff20-2a08-47b1-84a7-c05c74afb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter máscara de movimento limpa\n",
    "def get_motion_mask(fg_mask, kernel_size=5):\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    \n",
    "    # Aplica threshold para obter uma imagem binária\n",
    "    _, thresh = cv2.threshold(fg_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Aplica mediana para reduzir o ruído\n",
    "    motion_mask = cv2.medianBlur(thresh, 5)\n",
    "    \n",
    "    # Aplica operações morfológicas de abertura e fechamento com kernel menor\n",
    "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel)\n",
    "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return motion_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf5931-fa9b-4210-a89f-8f091bd34967",
   "metadata": {},
   "source": [
    "### 2.2. `non_max_suppression`\n",
    "\n",
    "* **Objetivo:** Realizar a supressão de não-máximos (NMS, Non-Maximum Suppression) em um conjunto de caixas delimitadoras (bounding boxes) para eliminar detecções redundantes e manter apenas as detecções mais confiáveis.\n",
    "\n",
    "A função `non_max_suppression` é uma técnica essencial em visão computacional para eliminar detecções múltiplas de um mesmo objeto, mantendo apenas a detecção mais confiável. Isso é particularmente útil em tarefas como detecção de objetos, onde várias caixas delimitadoras podem se sobrepor, representando o mesmo objeto, mas com diferentes níveis de confiança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a21ed1-93f2-48f0-87ee-81db1ab1abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para realizar supressão de não-máximos\n",
    "def non_max_suppression(bboxes, scores, threshold=0.3):\n",
    "\n",
    "    # Extrair as coordenada x1, x2, y1 e y2 das caixas delimitadoras\n",
    "    x1 = bboxes[:, 0]\n",
    "    y1 = bboxes[:, 1]\n",
    "    x2 = bboxes[:, 2]\n",
    "    y2 = bboxes[:, 3]\n",
    "\n",
    "    # Calcula a área de cada caixa delimitadora\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\n",
    "    # Ordena os índices das caixas delimitadoras com base em seus scores de confiança em ordem decrescente (do maior para o menor).\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    # Seleção: Seleciona a caixa com o maior score\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        # Cálculo das Interseções\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        # Dimensões da Interseção: Calcula a largura (w) e altura (h) das regiões de interseção.\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # Área da Interseção: Calcula a área de interseção\n",
    "        inter = w * h\n",
    "\n",
    "        # IoU (Intersection over Union): Calcula o grau de sobreposição (IoU) entre a caixa selecionada e as outras caixas.\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        # Se o IoU for superior ao limiar threshold, as caixas serão consideradas sobrepostas e potencialmente redundantes\n",
    "        inds = np.where(ovr <= threshold)[0]\n",
    "\n",
    "        # Atualização: Atualiza a lista order removendo as caixas suprimidas.\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81f557-e208-4ad8-af93-9d4c0e0f94fa",
   "metadata": {},
   "source": [
    "### 2.3. `process_video`\n",
    "\n",
    "* **Objetivo:** Processar um vídeo, detectar movimento em frames específicos, aplicar supressão de não-máximos (NMS) para eliminar detecções redundantes e salvar os frames onde o movimento foi detectado.\n",
    "\n",
    "A função `process_video` é uma abordagem robusta para processar vídeos, detectando movimento, aplicando técnicas de supressão de não-máximos, e salvando os frames e um background calculado a partir do vídeo. Esta função é ideal para aplicações que exigem monitoramento de movimento em vídeos e processamento de detecção de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8447dc5-74d5-4cee-b2ad-86f368545b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal para processar o vídeo e detectar movimento\n",
    "def process_video(video_path, skip_frames=5, output_dir='./jupyter_notebooks/motion_detection/02-output'):\n",
    "\n",
    "    # Variáveis e Inicializações\n",
    "    motion_list = [None, None]\n",
    "    contour_area_threshold = 10000\n",
    "    var_threshold = 50\n",
    "    use_hist_eq = False\n",
    "\n",
    "    # Inicializa o subtrator de fundo MOG2 com parâmetros ajustados\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(varThreshold=var_threshold, detectShadows=True)\n",
    "\n",
    "    # Abre o vídeo. Se não for possível, a função exibe um erro e retorna.\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Erro ao abrir o vídeo {video_path}\")\n",
    "        return\n",
    "\n",
    "    # Extrai o nome do arquivo de vídeo\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "    # Define o caminho completo onde os frames processados e o background serão salvos.\n",
    "    video_output_dir = os.path.join(output_dir, video_name)\n",
    "\n",
    "    # Cria o diretório de saída, se ele não existir.\n",
    "    os.makedirs(video_output_dir, exist_ok=True)\n",
    "\n",
    "    # Contador de frames processados.\n",
    "    frame_count = 0\n",
    "\n",
    "    # Lista para armazenar os frames coloridos para posterior cálculo do background.\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Lê o próximo frame do vídeo. Se não houver mais frames, o loop é interrompido.\n",
    "        check, frame = video.read()\n",
    "        if not check:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Pula a detecção para alguns frames, se necessário, para reduzir a carga computacional.\n",
    "        if frame_count % skip_frames != 0:\n",
    "            continue\n",
    "\n",
    "        # Converte o frame atual para escala de cinza, o que é necessário para a subtração de fundo.\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Se ativado, aplica equalização de histograma para melhorar o contraste na imagem em escala de cinza.\n",
    "        if use_hist_eq:\n",
    "            gray = cv2.equalizeHist(gray)\n",
    "\n",
    "        # Aplica o subtrator de fundo MOG2 para obter a máscara de movimento.\n",
    "        fg_mask = back_sub.apply(gray)\n",
    "\n",
    "        # Armazena o frame original (em cores) na lista de frames.\n",
    "        frames.append(frame)\n",
    "\n",
    "        # Aplica a função `get_motion_mask` para limpar e processar a máscara de movimento.\n",
    "        motion_mask = get_motion_mask(fg_mask)\n",
    "\n",
    "        # Encontra contornos na máscara de movimento\n",
    "        cnts, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Lista de caixas delimitadoras que contêm movimento relevante.\n",
    "        detections = []\n",
    "        for contour in cnts:\n",
    "\n",
    "            # Filtra os contornos com base na área mínima (contour_area_threshold)\n",
    "            if cv2.contourArea(contour) < contour_area_threshold:\n",
    "                continue\n",
    "\n",
    "            # Calcula o retângulo delimitador para cada contorno relevante.\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            detections.append((x, y, x+w, y+h))\n",
    "\n",
    "        # Aplica supressão de não-máximos\n",
    "        detections = np.array(detections)\n",
    "        if len(detections) > 0:\n",
    "\n",
    "            # Extrai as coordenadas das caixas delimitadoras para aplicar supressão de não-máximos.\n",
    "            bboxes = detections[:, :4]\n",
    "\n",
    "            # Scores de confiança (todos iguais a 1, pois os scores reais não são fornecidos).\n",
    "            scores = np.ones((len(bboxes),))\n",
    "\n",
    "            # Resultados da supressão de não-máximos (índices das caixas que serão mantidas).\n",
    "            keep = non_max_suppression(bboxes, scores, threshold=0.3)\n",
    "            for i in keep:\n",
    "                (x, y, x2, y2) = bboxes[i]\n",
    "\n",
    "                # Desenha um retângulo verde ao redor das detecções mantidas.\n",
    "                cv2.rectangle(frame, (x, y), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "        # Salvando Frames com Movimento\n",
    "\n",
    "        # Atualiza a lista para refletir se movimento foi detectado nos últimos dois frames.\n",
    "        motion_list.append(len(detections) > 0)\n",
    "        motion_list = motion_list[-2:]\n",
    "\n",
    "        if len(detections) > 0:\n",
    "            frame_path = os.path.join(video_output_dir, f'frame_{frame_count}.jpg')\n",
    "\n",
    "            # Se movimento foi detectado, salva o frame atual em um arquivo JPG.\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            print(f\"Frame {frame_count} salvo com movimento detectado.\")\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    if frames:\n",
    "        # Calcula a imagem de background como a mediana de todos os frames capturados.\n",
    "        background = np.median(frames, axis=0).astype(np.uint8)\n",
    "\n",
    "        # Define nome e local.\n",
    "        background_path = os.path.join(video_output_dir, 'background.jpg')\n",
    "\n",
    "        # Salva o background calculado em um arquivo JPG.\n",
    "        cv2.imwrite(background_path, background)\n",
    "        print(f\"Background salvo em {background_path}\")\n",
    "\n",
    "    # Libera o vídeo e fecha todas as janelas do OpenCV.\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Imprime uma mensagem indicando que o processamento do vídeo foi concluído.\n",
    "    print(f\"Processamento do vídeo {video_path} concluído.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29da54-6725-42fd-9f74-03374fc0e6d8",
   "metadata": {},
   "source": [
    "## 3. Input e Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba38704b-7335-49f3-830b-59138bc554d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório contendo os vídeos no Google Drive\n",
    "videos_dir = os.getcwd() + '\\\\01-dataset' # mesmo resultado que os.path.join(os.getcwd(), '\\01-dataset')\n",
    "\n",
    "# Diretório de saída principal\n",
    "output_dir = os.getcwd() + '\\\\02-output' # mesmo resultado que os.path.join(os.getcwd(), '\\02-output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3d9bf-97a1-4b8c-97fa-903c5e140beb",
   "metadata": {},
   "source": [
    "### 3.1. Listagem de videos\n",
    "\n",
    "Varredura dos videos para renomeá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb378de7-4d2a-483e-9869-a1c5f0f57744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todos os arquivos de vídeo na pasta especificada\n",
    "video_extensions = ('.mov', '.mp4', '.avi', '.mkv')\n",
    "video_paths = [os.path.join(videos_dir, f) for f in os.listdir(videos_dir) if f.lower().endswith(video_extensions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1300cf1-048e-4baa-8a7f-fc262112c619",
   "metadata": {},
   "source": [
    "## 4. Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2034b360-c4a8-412b-b795-5d1a0ca3c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\carcara.mov\n",
      "Frame 1435 salvo com movimento detectado.\n",
      "Frame 1440 salvo com movimento detectado.\n",
      "Frame 1445 salvo com movimento detectado.\n",
      "Frame 1450 salvo com movimento detectado.\n",
      "Frame 1455 salvo com movimento detectado.\n",
      "Frame 1760 salvo com movimento detectado.\n",
      "Frame 1765 salvo com movimento detectado.\n",
      "Frame 1770 salvo com movimento detectado.\n",
      "Frame 1775 salvo com movimento detectado.\n",
      "Frame 1780 salvo com movimento detectado.\n",
      "Frame 1785 salvo com movimento detectado.\n",
      "Frame 1790 salvo com movimento detectado.\n",
      "Frame 1795 salvo com movimento detectado.\n",
      "Frame 1800 salvo com movimento detectado.\n",
      "Background salvo em C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\02-output\\carcara\\background.jpg\n",
      "Processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\carcara.mov concluído.\n",
      "Processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\carcara.mov finalizado.\n",
      "Iniciando processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\gamba.mov\n",
      "Frame 5 salvo com movimento detectado.\n",
      "Background salvo em C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\02-output\\gamba\\background.jpg\n",
      "Processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\gamba.mov concluído.\n",
      "Processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\gamba.mov finalizado.\n",
      "Iniciando processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\javaporco.mov\n",
      "Frame 1125 salvo com movimento detectado.\n",
      "Frame 1130 salvo com movimento detectado.\n",
      "Frame 1135 salvo com movimento detectado.\n",
      "Frame 1140 salvo com movimento detectado.\n",
      "Frame 1145 salvo com movimento detectado.\n",
      "Frame 1150 salvo com movimento detectado.\n",
      "Frame 1155 salvo com movimento detectado.\n",
      "Frame 1160 salvo com movimento detectado.\n",
      "Frame 1165 salvo com movimento detectado.\n",
      "Frame 1170 salvo com movimento detectado.\n",
      "Frame 1175 salvo com movimento detectado.\n",
      "Frame 1180 salvo com movimento detectado.\n",
      "Frame 1185 salvo com movimento detectado.\n",
      "Frame 1190 salvo com movimento detectado.\n",
      "Frame 1195 salvo com movimento detectado.\n",
      "Frame 1200 salvo com movimento detectado.\n",
      "Frame 1205 salvo com movimento detectado.\n",
      "Frame 1210 salvo com movimento detectado.\n",
      "Frame 1215 salvo com movimento detectado.\n",
      "Frame 1220 salvo com movimento detectado.\n",
      "Frame 1225 salvo com movimento detectado.\n",
      "Frame 1230 salvo com movimento detectado.\n",
      "Frame 1235 salvo com movimento detectado.\n",
      "Frame 1240 salvo com movimento detectado.\n",
      "Frame 1245 salvo com movimento detectado.\n",
      "Frame 1250 salvo com movimento detectado.\n",
      "Frame 1255 salvo com movimento detectado.\n",
      "Frame 1260 salvo com movimento detectado.\n",
      "Frame 1265 salvo com movimento detectado.\n",
      "Frame 1590 salvo com movimento detectado.\n",
      "Frame 1595 salvo com movimento detectado.\n",
      "Frame 1600 salvo com movimento detectado.\n",
      "Frame 1605 salvo com movimento detectado.\n",
      "Frame 1610 salvo com movimento detectado.\n",
      "Frame 1615 salvo com movimento detectado.\n",
      "Frame 1620 salvo com movimento detectado.\n",
      "Frame 1625 salvo com movimento detectado.\n",
      "Frame 1630 salvo com movimento detectado.\n",
      "Frame 1635 salvo com movimento detectado.\n",
      "Frame 1640 salvo com movimento detectado.\n",
      "Frame 1645 salvo com movimento detectado.\n",
      "Frame 1650 salvo com movimento detectado.\n",
      "Frame 1655 salvo com movimento detectado.\n",
      "Frame 1660 salvo com movimento detectado.\n",
      "Frame 1665 salvo com movimento detectado.\n",
      "Frame 1670 salvo com movimento detectado.\n",
      "Frame 1675 salvo com movimento detectado.\n",
      "Frame 1680 salvo com movimento detectado.\n",
      "Frame 1685 salvo com movimento detectado.\n",
      "Frame 1690 salvo com movimento detectado.\n",
      "Frame 1695 salvo com movimento detectado.\n",
      "Frame 1700 salvo com movimento detectado.\n",
      "Frame 1705 salvo com movimento detectado.\n",
      "Frame 1710 salvo com movimento detectado.\n",
      "Frame 1715 salvo com movimento detectado.\n",
      "Frame 1720 salvo com movimento detectado.\n",
      "Frame 1725 salvo com movimento detectado.\n",
      "Frame 1730 salvo com movimento detectado.\n",
      "Frame 1735 salvo com movimento detectado.\n",
      "Frame 1740 salvo com movimento detectado.\n",
      "Frame 1745 salvo com movimento detectado.\n",
      "Frame 1750 salvo com movimento detectado.\n",
      "Frame 1755 salvo com movimento detectado.\n",
      "Frame 1760 salvo com movimento detectado.\n",
      "Frame 1765 salvo com movimento detectado.\n",
      "Frame 1770 salvo com movimento detectado.\n",
      "Frame 1775 salvo com movimento detectado.\n",
      "Frame 1780 salvo com movimento detectado.\n",
      "Frame 1785 salvo com movimento detectado.\n",
      "Frame 1790 salvo com movimento detectado.\n",
      "Frame 1795 salvo com movimento detectado.\n",
      "Frame 1800 salvo com movimento detectado.\n",
      "Background salvo em C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\02-output\\javaporco\\background.jpg\n",
      "Processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\javaporco.mov concluído.\n",
      "Processamento do vídeo C:\\Users\\ander\\Documents\\jupyter_notebooks\\motion_detection\\01-dataset\\javaporco.mov finalizado.\n"
     ]
    }
   ],
   "source": [
    "# Processa cada vídeo\n",
    "for video_path in video_paths:\n",
    "    print(f\"Iniciando processamento do vídeo {video_path}\")\n",
    "    process_video(video_path, skip_frames=5, output_dir=output_dir)\n",
    "    print(f\"Processamento do vídeo {video_path} finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
